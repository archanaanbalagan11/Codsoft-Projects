# -*- coding: utf-8 -*-
"""Image captioning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OTze483mRDeN-s_F4c8AaQtgL4SpYMEI
"""

!pip install tensorflow pillow numpy

import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import tensorflow as tf
from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Dropout, add
from tensorflow.keras.models import load_model
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.text import Tokenizer
import pickle

!pip install diffusers transformers accelerate scipy -qq

from diffusers import StableDiffusionPipeline
import torch
import matplotlib.pyplot as plt

# Load a pre-trained text-to-image model
# This will download the model weights, which might take some time.
# You can choose different models from the Hugging Face Hub.
model_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)

# Move the model to GPU if available
if torch.cuda.is_available():
    pipe = pipe.to("cuda")

# Define the text prompt
prompt = "the dog is running in the water"

# Generate the image
# You can adjust the number of inference steps for different results
with torch.no_grad():
    image = pipe(prompt).images[0]

# Display the generated image
plt.imshow(image)
plt.axis('off')
plt.title(prompt)
plt.show()